---
title: "Week 4 - topics of the week"
author: 
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse) # require gives more informative errors than library
```

## Introduction

This week we're focused on building our ability to analyze data. We'll incorporate new functions from the dplyr package, and explore table joins. 

The information below augments the readings. Following this, you'll be in good shape to start this week's exercises. Let's get started!

### Readings (complete by class on Monday)

Required:

- [R for Data Science, section 5.6: Grouped Summaries](https://r4ds.had.co.nz/transform.html#grouped-summaries-with-summarise)
- [R for Data Science, chapter 13: Relational Data (relations between different datasets)](https://r4ds.had.co.nz/relational-data.html) 

Optional: 

- [`dplyr` lesson in Data Carpentry](https://datacarpentry.org/R-ecology-lesson/03-dplyr.html)
- [`dplyr` vignette (long form example document)](https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html): if you’re struggling, this provides additional examples that you can try on your own (and as a bonus they use a Star Wars data set). Package vignettes like this are an amazing resource for learning new packages, and evaluating their capabilities, once you get the basics.
- [R for Data Science, chapter 12: Tidy Data (tools for tidying data based on the principles of data organization)](https://r4ds.had.co.nz/tidy-data.html). In particular focus on sections [12.3 Pivoting](https://r4ds.had.co.nz/tidy-data.html#pivoting) and [12.4 Separating and uniting](https://r4ds.had.co.nz/tidy-data.html#separating-and-uniting). I plan to add in more examples for this next year. These functions might be necessary for some of your projects. We'll see... 


As you read through, my suggestion is to have the Rmd version of this document open in Posit where you can take notes on important functions/concepts and also code along with the examples. This way you’ll get a headstart on your cheat sheet for this week.

The below summarizes and provides an example, but feel free to copy in examples from the reading and tinker with them a bit.  

## Group-by function: Summarizing info based on type/characteristic

* provides ability to summarize information based on a variable
* combines rows into groups based on a column characteristic

`group_by(data_table, column_to_group_by)`

Let's start by activating the datasets package within R-studio. We're going to explore the sleep dataset. 

```{r}
library(datasets)
library(dplyr)
x <- sleep
?sleep
```

The dataset has 3 variables: 

- `extra`, is a numeric variable representing the increase in hours of sleep
- `group` is a categorical factor variable representing the	drug given
-	`ID` is another	factor for the patient ID

Suppose you want to know how the 2 drug treatment groups varied with respect to the extra hours of sleep. First we group the data by `group`, the drug given. 

```{r}
x_drug <- group_by(x,group)
```

Now you can use summarize function to calculate statistics for each group within the dataset. Here, we only have 2 groups so it's a simple example. 

```{r}
# summarize the number of rows for each group
summarize(x_drug, N = n())

```

Or with a pipe (also note that you can us the American or British/New Zealander spelling)
```{r}
x_rows <-
  x_drug %>%
  summarise(N = n())
x_rows 
```

The result here is trivial, but imagine if you had a larger dataset, like the Dipodomys survey from last week. One technique in coding is to start with something small, where you can easily hand-calculate the answer. 

Let's look at other functions you can use within `summarize`:

* basic stats: https://www.dummies.com/education/math/statistics/base-r-statistical-functions/

* `sum()` 
* `mean()`
* `var()`
* `sd()`
* `range()`
* `cor()`
* `min()`
* `summary()`
* `max`
* `quantile`
* `median`

Let's look at the median number of extra sleep hours:

```{r}
x_rows <- 
  x_drug %>%
  summarize(median_sleep = median(extra))
x_rows
```

Now let's look at what would happen if there was missing data by changing a value:

```{r}
# summarize the number of rows for each group
x_drug[1,1] = NA # Oh I used `=` here to assign this, 
# the assignment arrows, `<-` or `->`, are generally best-coding 
# practice as they differentiate variables and objects, from function 
# arguments
```

Now, if we implement the summarize command for the median sleep we'll obtain a NA value:

```{r}
x_rows <- 
  x_drug %>% 
  summarize(median_sleep = median(extra))
x_rows
```

So what can we do? Start by adding a na.rm = TRUE command.

```{r}
x_rows <- 
  x_drug %>% 
  summarize(median_sleep = median(extra, na.rm = TRUE))
x_rows
```

If you still had NaN (depends on your dataset), you could filter the data: filter(dataset, !is.na(variable))


## Joins within `dplyr`

Within Biological Systems Engineering and the larger field, there are many times when we use multiple tables to reduce redundant data. Imagine you have a very large table that repeats double-precision data over and over again, resulting in a dataset that occupies more computer memory. While modern computers are incredible in their storage capacity, I can attest that processing speed and memory allocation is and will still be a consideration in your work. Here, we're going to explore how you can join tables using a common "key" or relation. 

Let's illustrate this using data using data we've used last week. 

We'll first read each of these into the workspace:

```{r}
plots <- read.csv("plots.csv")
species <- read.csv("species.csv")
surveys <- read.csv("surveys.csv")
```

Note that when you do this, there are 24 plots, 54 types of species, but 35,549 lines of data in the species dataset!

What is the column that links the plots and surveys dataset? 

`plot_id`!

What is the column that links the surveys dataset with the species?

`species_id`!

If we want to combine the dataset, let's look at how we would do this. We'll employ the command:

`inner_join`

From help:

The mutating joins add columns from dataset `y` to dataset `x`, matching rows based on the keys:

* `inner_join()`: includes all rows in `x` and `y`.

* `left_join()`: includes all rows in `x`.

* `right_join()`: includes all rows in `y`.

* `full_join()`: includes all rows in `x` or `y`.

* If a row in `x` matches multiple rows in `y`, all the rows in `y` will be returned once for each matching row in `x`.

The [dplyr cheat sheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) (also up in the Help>Cheat Sheets menu) demonstrates this visually.

If you want to include the detailed names contained within the species table, use an inner join and join based on the common variable species_id. You end up with 3 additional variables that are within the species table.

```{r}
combo <- inner_join(surveys, species, by="species_id")
```

If you wanted to join all three tables together:

```{r}
combo2 <- inner_join(combo, plots, by="plot_id")
```


## Converting between data-frames and vectors

Data frames are really just a bunch of vectors grouped together into columns. 

# Extract a vector from a data-frame

If you want to extract a single column, use the name of the dataframe followed by a $ sign and the variable name. For example, suppose you have the following dataset:


```{r}
x <- data.frame(state.x77)
```

This comes from the datasets package. 

Now, let's extract the population and income columns into 2 single vector:

```{r}
x2 <- x$Population
x3 <- x$Income
```

If you wanted to recombined these 2 vectors into a dataframe, use the data.frame function:

```{r}
x_data <- data.frame(x2,x3)
```

You could also add another column as follows. Here, the new column is called newcol with a value of 4 in every row.

```{r}
x_data <- data.frame(x_data,newcol=4)
```

That's all for now folks - you're ready for the exercises!